[
  {
    "objectID": "posts/spam/index.html",
    "href": "posts/spam/index.html",
    "title": "I deployed a spam detector online!",
    "section": "",
    "text": "Try it out now!\n\n\n\nThe model is already deployed, check it out here!\nYou can visit the repository of the project here.\n\n\nYou just need to input the text of the sms, whereupon the model outputs a prediction (spam or ham) along with the probability that it is true.\nI created this project using Django and Heroku. Thanks to this, the code is modular, easy to read and, above all, to maintain.\nThe data for training is publicly available online."
  },
  {
    "objectID": "posts/recipes/analysis.html",
    "href": "posts/recipes/analysis.html",
    "title": "High-traffic recipes prediction",
    "section": "",
    "text": "Note\n\n\n\nI made a presentation about this project, you can see the slides here.\nThe repository of the project is here."
  },
  {
    "objectID": "posts/recipes/analysis.html#background",
    "href": "posts/recipes/analysis.html#background",
    "title": "High-traffic recipes prediction",
    "section": "Background",
    "text": "Background\nTasty Bytes is a small company that publishes recipes on the internet and is in search of its own identity. Its home page displays different recipes that they think might catch the attention of its visitors. Some generate high traffic, while others are not as successful.\nThe company is starting to grow and would like to feature better recipes on its home page. To achieve this, it has collected information about the behaviour of its customers.\nThe goal is to predict which recipes will produce high website traffic. Ideally, 80% of the time a recipe is displayed on the home page, it should generate high traffic. Additionally, the business wants to avoid showing too many recipes that generate little traffic.\n\nDataset\nTasty Bytes has collected some data from the recipes on the website. As the project is just starting, it is not ruled out to compile other aspects of the recipes in the future. For now, we have the following information for each recipe: - recipe (id): The ID of the recipe in the database. - servings (integer): Number of servings of the recipe. - calories (numeric): Calories per serving measured in kcal. - carbohydrate (numeric): Carbohydrates per serving measured in grams. - sugar (numeric): Sugar quantity per serving measured in grams. - protein (numeric): Proteins in grams per serving. - category (categorical): Category of the recipe. There are 10 possible groups: Lunch/Snacks, Beverages, Potato, Vegetable, Meat, Chicken, Pork, Dessert, Breakfast and One Dish Meal. - high_traffic (categorical): Whether the recipe has high traffic or not. This is the target variable.\n\n\nCode\nfrom pathlib import Path\n\nimport missingno as msno\nimport numpy as np\nimport pandas as pd\nimport pingouin as pg\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, make_scorer, roc_auc_score\nfrom sklearn.model_selection import KFold, train_test_split, GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nCode\nmy_palette = ['#3C7E00', '#D9B100', '#EC5800', '#003153', '#70778C'] * 2\nsns.set_theme(style='whitegrid')\nsns.set_palette(sns.color_palette(my_palette))\n\n\n\n\nCode\nplot_name = {\n    'calories': 'Calories',\n    'carbohydrate': 'Carbohydrate',\n    'sugar': 'Sugar',\n    'protein': 'Protein',\n    'category': 'Category',\n    'servings': 'Servings',\n    'high_traffic': 'High traffic'\n}\n\n\n\n\nCode\nimages_directory = Path('im')\nimages_directory.mkdir(exist_ok=True)\n\n\n\n\nCode\nrecipes = pd.read_csv(Path('data') / 'recipe_site_traffic_2212.csv')\nrecipes\n\n\n\n\n\n\n\n\n\nrecipe\ncalories\ncarbohydrate\nsugar\nprotein\ncategory\nservings\nhigh_traffic\n\n\n\n\n0\n1\nNaN\nNaN\nNaN\nNaN\nPork\n6\nHigh\n\n\n1\n2\n35.48\n38.56\n0.66\n0.92\nPotato\n4\nHigh\n\n\n2\n3\n914.28\n42.68\n3.09\n2.88\nBreakfast\n1\nNaN\n\n\n3\n4\n97.03\n30.56\n38.63\n0.02\nBeverages\n4\nHigh\n\n\n4\n5\n27.05\n1.85\n0.80\n0.53\nBeverages\n4\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n942\n943\n1161.00\n5.31\n22.39\n44.22\nLunch/Snacks\n2\nNaN\n\n\n943\n944\nNaN\nNaN\nNaN\nNaN\nPotato\n2\nHigh\n\n\n944\n945\n951.74\n29.42\n3.57\n13.87\nPork\n2\nHigh\n\n\n945\n946\n266.61\n35.77\n0.97\n8.07\nPotato\n6\nHigh\n\n\n946\n947\n184.56\n45.21\n6.20\n0.03\nBeverages\n4\nNaN\n\n\n\n\n947 rows × 8 columns\n\n\n\n\n\nCode\nrecipes.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 947 entries, 0 to 946\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   recipe        947 non-null    int64  \n 1   calories      895 non-null    float64\n 2   carbohydrate  895 non-null    float64\n 3   sugar         895 non-null    float64\n 4   protein       895 non-null    float64\n 5   category      947 non-null    object \n 6   servings      947 non-null    object \n 7   high_traffic  574 non-null    object \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 59.3+ KB\n\n\n\n\nCode\nrecipes.describe()\n\n\n\n\n\n\n\n\n\nrecipe\ncalories\ncarbohydrate\nsugar\nprotein\n\n\n\n\ncount\n947.000000\n895.000000\n895.000000\n895.000000\n895.000000\n\n\nmean\n474.000000\n435.939196\n35.069676\n9.046547\n24.149296\n\n\nstd\n273.519652\n453.020997\n43.949032\n14.679176\n36.369739\n\n\nmin\n1.000000\n0.140000\n0.030000\n0.010000\n0.000000\n\n\n25%\n237.500000\n110.430000\n8.375000\n1.690000\n3.195000\n\n\n50%\n474.000000\n288.550000\n21.480000\n4.550000\n10.800000\n\n\n75%\n710.500000\n597.650000\n44.965000\n9.800000\n30.200000\n\n\nmax\n947.000000\n3633.160000\n530.420000\n148.750000\n363.360000\n\n\n\n\n\n\n\nThe dataset has several missing values. The number of missing values and its proportion per each variable is:\n\n\nCode\nrecipes.isna().sum()\n\n\nrecipe            0\ncalories         52\ncarbohydrate     52\nsugar            52\nprotein          52\ncategory          0\nservings          0\nhigh_traffic    373\ndtype: int64\n\n\n\n\nCode\nrecipes.isna().mean()\n\n\nrecipe          0.000000\ncalories        0.054910\ncarbohydrate    0.054910\nsugar           0.054910\nprotein         0.054910\ncategory        0.000000\nservings        0.000000\nhigh_traffic    0.393875\ndtype: float64"
  },
  {
    "objectID": "posts/recipes/analysis.html#data-validation",
    "href": "posts/recipes/analysis.html#data-validation",
    "title": "High-traffic recipes prediction",
    "section": "Data Validation",
    "text": "Data Validation\n\nrecipe\nThe column recipe is the ID of the recipe. It is unique and has the same number of unique values as the number of rows in the dataset. So, it can be removed.\n\n\nCode\nassert recipes['recipe'].min() &gt;= 1\nassert recipes['recipe'].is_unique\nassert recipes['recipe'].nunique() == len(recipes)\nrecipes.drop(columns='recipe', inplace=True)\n\n\n\n\ncalories, carbohydrate, sugar, protein\nThese are some numeric columns with missing values.\n\n\nCode\nnutrition_columns = ['calories', 'carbohydrate', 'sugar', 'protein']\n\n\n\n\nCode\nrecipes[nutrition_columns].describe()\n\n\n\n\n\n\n\n\n\ncalories\ncarbohydrate\nsugar\nprotein\n\n\n\n\ncount\n895.000000\n895.000000\n895.000000\n895.000000\n\n\nmean\n435.939196\n35.069676\n9.046547\n24.149296\n\n\nstd\n453.020997\n43.949032\n14.679176\n36.369739\n\n\nmin\n0.140000\n0.030000\n0.010000\n0.000000\n\n\n25%\n110.430000\n8.375000\n1.690000\n3.195000\n\n\n50%\n288.550000\n21.480000\n4.550000\n10.800000\n\n\n75%\n597.650000\n44.965000\n9.800000\n30.200000\n\n\nmax\n3633.160000\n530.420000\n148.750000\n363.360000\n\n\n\n\n\n\n\nThe minima are greater than zero, and the maxima are huge. Calories is the most spread variable. I will address the missing values right away, since it is the most important problem.\n\n\nMissing values\nThe columns have missing values in exactly the same observations! Only high_traffic has a different number of missing values.\n\n\nCode\nmsno.matrix(recipes.sort_values('calories'))\n\n\n&lt;Axes: &gt;\n\n\n\n\n\nWe have Missing Not at Random (MNAR), because the existence of missing values in the columns is perfectly correlated:\n\n\nCode\nmsno.heatmap(recipes[nutrition_columns])\n\n\n&lt;Axes: &gt;\n\n\n\n\n\nIt is possible that it was a problem in the collection process: perhaps these recipes were not correctly extracted from the database. I prefer talk with the team responsible for the data collection, but for now I will just remove these observations (around 5% of the data) .\n\n\nCode\nrecipes.dropna(subset=nutrition_columns, inplace=True)\n\n\n\n\nAnomaly detection\n\n\nCode\ndef detect_outliers(series):\n    q1 = series.quantile(0.25)\n    q3 = series.quantile(0.75)\n    iqr = q3 - q1\n    lower_bound = q1 - 1.5 * iqr\n    upper_bound = q3 + 1.5 * iqr\n    return (series &lt; lower_bound) | (series &gt; upper_bound)\n\n\n\n\nCode\nfor col in nutrition_columns:\n    print(f'Outliers in {col}: {detect_outliers(recipes[col]).sum()}')\n\n\nOutliers in calories: 47\nOutliers in carbohydrate: 58\nOutliers in sugar: 79\nOutliers in protein: 77\n\n\nThere are outliers in all nutritional columns. In fact, the columns are highly skewed to the right, that is, the skewness is positive and greater than 1:\n\n\nCode\nrecipes[nutrition_columns].skew()\n\n\ncalories        2.036151\ncarbohydrate    3.756980\nsugar           4.223352\nprotein         3.509453\ndtype: float64\n\n\n\n\nCode\nrecipes[nutrition_columns].hist()\n\n\narray([[&lt;Axes: title={'center': 'calories'}&gt;,\n        &lt;Axes: title={'center': 'carbohydrate'}&gt;],\n       [&lt;Axes: title={'center': 'sugar'}&gt;,\n        &lt;Axes: title={'center': 'protein'}&gt;]], dtype=object)\n\n\n\n\n\n\n\nCode\nrecipes[nutrition_columns].boxplot()\n\n\n&lt;Axes: &gt;\n\n\n\n\n\nThe outliers might be actual values, so it is best to discuss with the team to be certain. During the analysis I will keep the outliers, but in the model fit I will control the skewness by log transforming the data, as shown here:\n\n\nCode\nnp.log(recipes[nutrition_columns] + 1).hist()\n\n\narray([[&lt;Axes: title={'center': 'calories'}&gt;,\n        &lt;Axes: title={'center': 'carbohydrate'}&gt;],\n       [&lt;Axes: title={'center': 'sugar'}&gt;,\n        &lt;Axes: title={'center': 'protein'}&gt;]], dtype=object)\n\n\n\n\n\n\n\ncategory\nThere are 10 possible groups of recipes. Nevertheless, I found 11 unique values in the column.\n\n\nCode\nrecipes['category'].value_counts()\n\n\ncategory\nBreakfast         106\nChicken Breast     94\nBeverages          92\nPotato             83\nLunch/Snacks       82\nVegetable          78\nDessert            77\nMeat               74\nPork               73\nChicken            69\nOne Dish Meal      67\nName: count, dtype: int64\n\n\nThe value Chicken Breast is a typo of Chicken. I will replace it.\n\n\nCode\nrecipes['category'] = (recipes['category']\n                       .replace({'Chicken Breast': 'Chicken'})\n                       .astype('category'))\nrecipes['category'].value_counts()\n\n\ncategory\nChicken          163\nBreakfast        106\nBeverages         92\nPotato            83\nLunch/Snacks      82\nVegetable         78\nDessert           77\nMeat              74\nPork              73\nOne Dish Meal     67\nName: count, dtype: int64\n\n\n\n\nservings\n\n\nCode\nrecipes['servings'].value_counts()\n\n\nservings\n4               365\n6               184\n2               174\n1               169\n4 as a snack      2\n6 as a snack      1\nName: count, dtype: int64\n\n\nI will remove unnecessary characters and convert to numeric data type.\n\n\nCode\nrecipes['servings'] = recipes['servings'].str.replace(r'\\D+', '', regex=True).astype(int)\nrecipes['servings'].value_counts()\n\n\nservings\n4    367\n6    185\n2    174\n1    169\nName: count, dtype: int64\n\n\n\n\nhigh_traffic\n\n\nCode\nrecipes['high_traffic'].value_counts()\n\n\nhigh_traffic\nHigh    535\nName: count, dtype: int64\n\n\nThe missing values correspond to recipes that do not have high traffic, so I will impute and convert to categorical for ease of analysis (in modelling I will encode them properly).\n\n\nCode\nrecipes['high_traffic'] = (recipes['high_traffic']\n                           .replace({'High': 'Yes'})\n                           .fillna('No')\n                           .astype('category')\n                           .cat.reorder_categories(['Yes', 'No'])\n                           )\nrecipes['high_traffic'].value_counts()\n\n\nhigh_traffic\nYes    535\nNo     360\nName: count, dtype: int64\n\n\n\n\nSummary\n\nrecipe: id of the recipe, unique and sequential, was removed\ncalories, carbohydrate, sugar. protein : nearly 5% of the data was removed due to missing values, the columns are skewed to the right and have outliers, I will log transform the data in the model fit. The minima were greater than zero as expected.\ncategory: there was a typo in the category Chicken Breast, I replaced it. The column was converted to categorical. All the other ten categories are correct: Lunch/Snacks, Beverages, Potato, Vegetable, Meat, Chicken, Pork, Dessert, Breakfast and One Dish Meal.\nservings: there were some spelling problems that I quickly fix, no information loss.\nhigh_traffic: the missing values correspond to recipes that do not have high traffic, so I imputed and converted to categorical."
  },
  {
    "objectID": "posts/recipes/analysis.html#data-analysis",
    "href": "posts/recipes/analysis.html#data-analysis",
    "title": "High-traffic recipes prediction",
    "section": "Data Analysis",
    "text": "Data Analysis\nThere are quite a few variables, so I will analyse them separately depending on their type.\n\nDiscrete variables\n\n\nCode\nplot_traffic = sns.countplot(data=recipes, x='high_traffic')\nplot_traffic.bar_label(plot_traffic.containers[0])\nplot_traffic.set(xlabel=plot_name['high_traffic'],\n                 ylabel='Count',\n                 title='Number of recipes by traffic')\nplot_traffic.figure.savefig(images_directory / \"traffic.png\")\n\n\n\n\n\nThe target variable is unbalanced, recipes with high traffic are more frequent.\n\n\nCode\nplot_traffic_servings = sns.histplot(data=recipes,\n                                     x='servings',\n                                     hue='high_traffic',\n                                     discrete=True,\n                                     multiple='dodge')\nplot_traffic_servings.grid(axis='x')\nplot_traffic_servings.set(xlabel=plot_name['servings'],\n                          ylabel='Count',\n                          title='Number of recipes by servings')\nplot_traffic_servings.figure.savefig(images_directory / \"traffic_servings.svg\")\n\n\n\n\n\nRecipes with 4 servings are the most popular, so the main customers might be families. Get to know the customers better would be interesting to understand the traffic on the website! On the other hand, there are no recipes with 3 nor 5 servings. Why do not we offer recipes with these servings?\nThe different categories have a different number of recipes. So, I will show the proportion of recipes with high traffic in each category.\n\n\nCode\ntraffic_by_category = (\n    recipes\n    .groupby('category')['high_traffic']\n    .value_counts(normalize=True, sort=True)\n    .unstack()[['Yes']]\n    .reset_index()\n)\nplot_percent = sns.barplot(traffic_by_category,\n                           x='Yes',\n                           y='category',\n                           palette='summer',\n                           #palette=my_palette[2:3],\n                           order=traffic_by_category.sort_values('Yes', ascending=False)['category']\n                           )\nplot_percent.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\nplot_percent.set(xlabel='Proportion of high-traffic recipes',\n                 #title='Proportion of high-traffic recipes by category',\n                 ylabel=''\n                 )\nplot_percent.figure.savefig(images_directory /\"traffic_category.svg\")\n\n\n/var/folders/01/7w297lbs6v77_d56zq_nqjjc0000gn/T/ipykernel_23735/1286798689.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  .groupby('category')['high_traffic']\n/var/folders/01/7w297lbs6v77_d56zq_nqjjc0000gn/T/ipykernel_23735/1286798689.py:8: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  plot_percent = sns.barplot(traffic_by_category,\n\n\n\n\n\nThe more popular categories are by far Vegetable and Potato. The less popular is Beverages. It seems that people prefer to search for healthy recipes.\n\n\nContinuous variables\n\n\nCode\nplot_calories = sns.histplot(data=recipes, x='calories')\nplot_calories.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:,.0f}'.format(y)))\nplot_calories.set(xlabel=plot_name['calories'],\n                  ylabel='Count',\n                  title='Distribution of calories')\n\n\n[Text(0.5, 0, 'Calories'),\n Text(0, 0.5, 'Count'),\n Text(0.5, 1.0, 'Distribution of calories')]\n\n\n\n\n\nThe distribution is highly skewed to the right and there are outliers. Besides, a lot of recipes are low in calories (those in the vegetable category).\n\n\nCode\nplot_calories_kde = sns.kdeplot(data=recipes, x='calories', hue='high_traffic')\nplot_calories_kde.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:,.0f}'.format(y)))\nplot_calories_kde.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.2%}'.format(y)))\nplot_calories_kde.set(xlabel=plot_name['calories'],\n                      ylabel='Count',\n                      title='Distribution of calories by popularity')\n\n\n[Text(0.5, 0, 'Calories'),\n Text(0, 0.5, 'Count'),\n Text(0.5, 1.0, 'Distribution of calories by popularity')]\n\n\n\n\n\nIt looks like high-traffic recipes have more calories than low-traffic recipes. But the distributions are quite similar.\n\n\nCode\nplot_calories_box = sns.boxplot(data=recipes,\n                                x='calories',\n                                y='category',\n                                hue='high_traffic')\nplot_calories_box.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:,.0f}'.format(y)))\nplot_calories_box.set(xlabel=plot_name['calories'],\n                      ylabel='',\n                      title='Distribution of calories by category')\n\n\n[Text(0.5, 0, 'Calories'),\n Text(0, 0.5, ''),\n Text(0.5, 1.0, 'Distribution of calories by category')]\n\n\n\n\n\nThe distribution of calories is different for each category. Beverages and vegetables have less calories, while meat and pork present more calories, as expected. Additionally, high-traffic recipes do not behave very differently from low-traffic recipes.\nThe other continuous variables behave similarly, so it is time to move on to review the relationships between the variables.\n\n\nRelationships\n\n\nCode\nplot_calories_protein = sns.scatterplot(data=recipes,\n                                        x='calories',\n                                        y='protein',\n                                        alpha=0.6,\n                                        hue='high_traffic')\nplot_calories_protein.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:,.0f}'.format(y)))\nplot_calories_protein.set(xlabel=plot_name['calories'],\n                          ylabel=plot_name['protein'],\n                          title=plot_name['protein'] + ' vs ' + plot_name['calories'])\n\nplot_calories_protein.figure.savefig(images_directory /\"scatter.svg\")\n\n\n\n\n\nCalories and protein do not exhibit a linear relationship and do not effectively separete high-traffic recipes from low-traffic recipes. Numeric variables might not be enough to explain the traffic, but hypothesis test will help to determine it. But before, it is important to check the relationship between all the numeric variables.\n\n\nCode\ng = sns.PairGrid(recipes, hue='high_traffic')\ng.map_upper(sns.scatterplot)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.kdeplot)\ng.add_legend()\n\n\n&lt;seaborn.axisgrid.PairGrid at 0x137f48c10&gt;\n\n\n\n\n\n\nThere are not linear relationships between the variables.\nservings is the unique variable that seems to separate high-traffic recipes from low-traffic recipes.\nThe distribution of the variables is similar to each other.\nEach variable provides different information but it is not enough to explain the target.\nservings do not exhibit any interesting relationship with the other variables.\n\n\n\nCode\nsns.heatmap(recipes.select_dtypes('number').corr(),\n            vmin=-1,\n            vmax=1,\n            annot=True,\n            fmt='.1%',\n            cmap='RdBu')\n\n\n&lt;Axes: &gt;\n\n\n\n\n\nThe correlation between the variables is low, so it is not necessary to remove any of them. Unfortunately they do not provide enough information to explain the traffic. In consequence, the company should collect new variables."
  },
  {
    "objectID": "posts/recipes/analysis.html#statistical-analysis",
    "href": "posts/recipes/analysis.html#statistical-analysis",
    "title": "High-traffic recipes prediction",
    "section": "Statistical analysis",
    "text": "Statistical analysis\nSo far, numeric variables do not provide enough information to explain the target. So, I will perform a hypothesis test to determine if there is a difference in means between high-traffic recipes and low-traffic recipes. I have already examined calories, so I will focus on the other variables.\n\n\nCode\nnum = recipes.drop(columns=['calories', 'servings', 'category']).melt(id_vars='high_traffic')\nsns.violinplot(data=num, y='variable', x='value', hue='high_traffic')\n\n\n&lt;Axes: xlabel='value', ylabel='variable'&gt;\n\n\n\n\n\nThe shape of the distributions is similar for each variable and does not change with the traffic. This suggests that there is not a difference between high-traffic recipes and low-traffic recipes. But I will perform a t test to confirm it. It is enough to only consider one variable, so I will choose carbohydrate.\n\n\nCode\ncarbohydrate_df = recipes[['carbohydrate', 'high_traffic']].sort_values(by='carbohydrate')\ncarbohydrate_df['carbohydrate'] = np.log(carbohydrate_df['carbohydrate'])\ngrouped = carbohydrate_df.groupby('high_traffic')['carbohydrate']\n\n\n/var/folders/01/7w297lbs6v77_d56zq_nqjjc0000gn/T/ipykernel_23735/3661453220.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped = carbohydrate_df.groupby('high_traffic')['carbohydrate']\n\n\n\n\nCode\ngrouped.size()\n\n\nhigh_traffic\nYes    535\nNo     360\nName: carbohydrate, dtype: int64\n\n\n\n\nCode\ngrouped.mean()\n\n\nhigh_traffic\nYes    2.929196\nNo     2.792631\nName: carbohydrate, dtype: float64\n\n\nThe means are quite close.\n\n\nCode\ngrouped.std()\n\n\nhigh_traffic\nYes    1.398557\nNo     1.290192\nName: carbohydrate, dtype: float64\n\n\nAlso, the standard deviations are similar.\n\n\nCode\nplot_carbohydrate = sns.kdeplot(carbohydrate_df, x='carbohydrate', hue='high_traffic')\nplot_carbohydrate.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.2%}'.format(y)))\nplot_carbohydrate.set(xlabel=plot_name['carbohydrate'],\n                      ylabel='Count',\n                      title='Distribution of log-carbohydrate')\n\n\n[Text(0.5, 0, 'Carbohydrate'),\n Text(0, 0.5, 'Count'),\n Text(0.5, 1.0, 'Distribution of log-carbohydrate')]\n\n\n\n\n\nAfter applying the logarithm to stabilize the variance, the distributions are different in their highest points.\n\n\nCode\ndef log_transform(col, yes):\n    if yes:\n        series = recipes[recipes['high_traffic'] == 'Yes'][col]\n    else:\n        series = recipes[recipes['high_traffic'] == 'No'][col]\n    return np.log(series).values\n\n\ndef pvalue(col):\n    test = pg.ttest(log_transform(col, yes=True),\n                    log_transform(col, yes=False),\n                    alternative='two-sided')\n    return float(test['p-val'][0])\n\n\n\n\nCode\nprint(f\"The p-value for carbohydrate is {pvalue('carbohydrate'):.2%}\")\n\n\nThe p-value for carbohydrate is 13.38%\n\n\n/var/folders/01/7w297lbs6v77_d56zq_nqjjc0000gn/T/ipykernel_23735/886310270.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  return float(test['p-val'][0])\n\n\nSo, we fail to reject the null hypothesis that the mean of log-carbohydrate is the same for high traffic and low traffic recipes. That is, the evidence is not strong enough to say that both samples come from different distributions.\n\nPCA\nPrincipal component analysis is used here as a exploratory tool but it may help to posit new predictors.\n\n\nCode\nfeatures = recipes.drop(columns=['category', 'high_traffic'])\nexploratory_pipe = make_pipeline(StandardScaler(), PCA())\nscores = exploratory_pipe.fit_transform(features)\nscores\n\n\narray([[ 0.65426384, -0.65146186, -0.12452776, -0.8480854 ,  0.18465792],\n       [-0.52863982,  1.18388874, -0.77489515, -0.53798623, -1.0438762 ],\n       [ 1.80173003, -0.02830077, -0.04476441,  1.38775645, -0.01580786],\n       ...,\n       [-0.77684631,  0.67283243, -0.49149572, -0.20558992, -0.94864049],\n       [ 0.32592996, -1.35255814,  0.7742397 , -0.48519653, -0.12152069],\n       [ 0.70429131, -0.38459335,  0.06807003, -0.53266432, -0.06876487]])\n\n\n\n\nCode\nloadings = exploratory_pipe.named_steps['pca'].components_\nloadings_df = pd.DataFrame(loadings.T,\n                           index=features.columns,\n                           columns=[f'PCA{i + 1}' for i in range(5)])\nloadings_df\n\n\n\n\n\n\n\n\n\nPCA1\nPCA2\nPCA3\nPCA4\nPCA5\n\n\n\n\ncalories\n-0.578795\n0.250718\n0.222501\n0.216261\n-0.711239\n\n\ncarbohydrate\n0.277938\n0.570468\n0.657894\n-0.401306\n0.058704\n\n\nsugar\n0.487713\n0.269203\n0.067710\n0.827178\n-0.029301\n\n\nprotein\n-0.586355\n0.151353\n0.238297\n0.301640\n0.696784\n\n\nservings\n0.077916\n-0.718561\n0.675499\n0.130290\n-0.065769\n\n\n\n\n\n\n\n\n\nCode\nscores_df = pd.DataFrame(data=scores, columns=loadings_df.columns)\n\n\n\n\nCode\nplot_pca = sns.scatterplot(data=scores_df,\n                           x='PCA1',\n                           y='PCA2',\n                           hue=recipes['high_traffic'],\n                           alpha=0.5)\nplot_pca.set(title='Two main PCA by popularity')\n\n\n[Text(0.5, 1.0, 'Two main PCA by popularity')]\n\n\n\n\n\nThe two main PCA components do not seem to separate the two classes very well. Even though they are not great predictors, we can still look at the loadings to see which variables are more important in each component and if they provide similar information.\n\n\nCode\nmain_pca = loadings_df.iloc[:, :2].reset_index(names='var')\nmain_pca\n\n\n\n\n\n\n\n\n\nvar\nPCA1\nPCA2\n\n\n\n\n0\ncalories\n-0.578795\n0.250718\n\n\n1\ncarbohydrate\n0.277938\n0.570468\n\n\n2\nsugar\n0.487713\n0.269203\n\n\n3\nprotein\n-0.586355\n0.151353\n\n\n4\nservings\n0.077916\n-0.718561\n\n\n\n\n\n\n\n\n\nCode\nsns.set_palette(sns.color_palette(my_palette[1:2]))\nsns.scatterplot(main_pca, x=\"PCA1\", y=\"PCA2\", s=100)\nfor line in range(main_pca.shape[0]):\n    plt.text(main_pca.iloc[line, 1] - 0.055,\n             main_pca.iloc[line, 2] - 0.07,\n             main_pca.iloc[line, 0],\n             horizontalalignment='left',\n             color='green',\n             size='medium',\n             weight='semibold')\nplt.show()\nsns.set_palette(sns.color_palette(my_palette))\n\n\n\n\n\n\nCalories and protein are the most important variables in the first component and are quite close to each other, so they contain similar information. They can be combined into a single variable.\nCarbohydrate and sugar have a similar behaviour in the second component.\nThe first component do not assign a lot of importance to servings, but the second component does.\nServings is clearly different from the other predictors and provides new information."
  },
  {
    "objectID": "posts/recipes/analysis.html#modelling",
    "href": "posts/recipes/analysis.html#modelling",
    "title": "High-traffic recipes prediction",
    "section": "Modelling",
    "text": "Modelling\nSince the company wants to predict which recipes are popular, it is a supervised learning problem. The target variable is binary, so it is a classification problem.\n\nBusiness metrics\n\nTasty Bytes desires to correctly predict high traffic recipes 80% of the time: this is the most important metric. In other words, 8 out of 10 recipes that are predicted to have high traffic should actually have high traffic. This metric is precision.\nHigh-traffic is the important class, so it will be the positive class.\nTasty Bytes also wants to minimize the chance of showing unpopular recipes. In other words, the low-traffic recipes should be detected as such. This metric is specificity.\n\n\n\nPreparing the data\nBefore modelling, I will preprocess the data. - To stabilize the variance, I will apply the logarithm to the numerical variables. - I will also use one-hot encoding for the categorical variables. - The target variable will be encoded as 0 and 1. - The data will be split into train and test sets. The test set will be used only at the end of the modelling process to evaluate the final model, and its size is 20% of the original data. - The train set will be used for cross-validation and hyperparameter tuning. - The results will be reproducible by setting a seed with the most simple value, 1 (so, there is no chance of manipulating the final metrics).\n\n\nCode\nfeatures = recipes.drop(columns=['high_traffic'])\nfeatures = pd.get_dummies(features, drop_first=True, dtype='int32')\ntarget = recipes['high_traffic'].replace({'Yes': 1, 'No': 0}).astype('int32')\n\n\n\n\nCode\nseed = 1\nX = np.log(features.values + 1)\ny = target.values\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    stratify=y,\n                                                    test_size=0.2,\n                                                    random_state=seed)\nfold_info = KFold(n_splits=5, shuffle=True, random_state=seed)\n\n\nPrecision and specificity will be used as scoring metrics. The roc auc score is a good option for training because it incorporates information about the two classes and helps to control its unbalance.\n\n\nCode\ndef specificity(y_true, y_pred):\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    return tn / (tn + fp)\n\n\nmy_scoring = {'precision': make_scorer(precision_score),\n              'roc_auc': make_scorer(roc_auc_score),\n              'specificity': make_scorer(specificity)}\n\n\n\n\nBase model\n\nNaive Bayes is a simple model that can be used as a baseline.\nIt is a good choice for the first model because it is fast and does not require so much hyperparameter tuning.\nAlso, I will use PCA to reduce the number of predictors (in consequence, it is needed to standardize them at the beginning).\n\n\n\nCode\npipe_naive = make_pipeline(StandardScaler(), PCA(), GaussianNB())\ngrid = {\n    'gaussiannb__var_smoothing': [1e-12, 1e-10, 1e-9, 1e-8]\n}\nnb = GridSearchCV(pipe_naive,\n                  grid,\n                  cv=fold_info,\n                  scoring=my_scoring,\n                  refit='roc_auc',\n                  return_train_score=True,\n                  n_jobs=-1,\n                  verbose=1)\nnb.fit(X_train, y_train)\nprint(nb.best_params_)\nprint(nb.best_score_) # score is the metric in the parameter `scoring`\n\n\nFitting 5 folds for each of 4 candidates, totalling 20 fits\n{'gaussiannb__var_smoothing': 1e-12}\n0.7374247680537823\n\n\nAfter hyperparameter tuning, the best model is the one with var_smoothing=1e-12. So now I will fit the model with that parameter and evaluate it with the test set.\n\n\nCode\nprint(f\"Precision: {precision_score(y_test, nb.predict(X_test)):0.2%} \")\nprint(f\"Specificity: {specificity(y_test, nb.predict(X_test)):0.2%} \")\n\n\nPrecision: 85.29% \nSpecificity: 79.17% \n\n\nThe precision is greater than 85%, which is the desired value. The specificity is close to 80%. So, the model is good enough to be used as a baseline.\n\n\nCode\ncm_nb = confusion_matrix(y_test, nb.predict(X_test), labels=nb.classes_)\ncm_nb\n\n\narray([[57, 15],\n       [20, 87]])\n\n\n\n\nCode\ncm_nb = ConfusionMatrixDisplay.from_estimator(nb,\n                                              X_test,\n                                              y_test,\n                                              display_labels=['Low-Traffic', 'High-Traffic'],\n                                              cmap='YlGn',\n                                              colorbar=False)\ncm_nb.figure_.savefig(images_directory / 'conf_nb.svg')\n\n\n\n\n\nConfusion matrix is a good way to visualize the results. It shows that the model is predicting more high-traffic recipes than low-traffic recipes. This is good because the most important metric is precision. Naive bayes performed quite well but it is not the best option to show the most important variables to the business. So, I will try a tree-based model.\n\n\nAlternative model\n\nRandom forest is a good option because it is fast and can be used to show the most important variables.\nIt does not need preprocessing\nHyperparameter tuning can help to improve the model.\n\n\n\nCode\n\npipe_rf = make_pipeline(RandomForestClassifier(random_state=seed, n_jobs=-1))\ngrid = {\n    'randomforestclassifier__n_estimators': [5, 10, 50, 100],\n    'randomforestclassifier__max_depth': [3, 10, 25],\n    'randomforestclassifier__max_features': ['sqrt', 'log2'],\n    'randomforestclassifier__criterion': ['gini', 'entropy'],\n    'randomforestclassifier__class_weight': ['balanced', 'balanced_subsample']\n}\nrf = GridSearchCV(pipe_rf,\n                  grid,\n                  cv=fold_info,\n                  scoring=my_scoring,\n                  refit='precision',\n                  return_train_score=True,\n                  n_jobs=-1,\n                  verbose=1)\nrf.fit(X_train, y_train)\nprint(rf.best_params_)\nprint(rf.best_score_)\n\n\nFitting 5 folds for each of 96 candidates, totalling 480 fits\n{'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__n_estimators': 100}\n0.7862318851417894\n\n\nAfter hyperparameter tuning, the best model is the one with criterion='gini', max_depth=3, max_features='sqrt' and n_estimators=100. So now I will fit the model with the best hyperparameters and evaluate it with the test set.\n\n\nCode\nprint(f\"Precision: {precision_score(y_test, rf.predict(X_test)):0.2%} \")\nprint(f\"Specificity: {specificity(y_test, rf.predict(X_test)):0.2%} \")\n\n\nPrecision: 84.38% \nSpecificity: 79.17% \n\n\nThe precision is close to 85%, which is best than the desired value. The specificity is close to 80%. So, the model is adequate.\n\n\nCode\ncm_rf = confusion_matrix(y_test, rf.predict(X_test))\ncm_rf\n\n\narray([[57, 15],\n       [26, 81]])\n\n\n\n\nCode\ncm_rf = ConfusionMatrixDisplay.from_estimator(rf,\n                                              X_test,\n                                              y_test,\n                                              display_labels=['Low-Traffic', 'High-Traffic'],\n                                              cmap='YlGn',\n                                              colorbar=False)\ncm_rf.figure_.savefig(images_directory / 'conf_rf.svg')\n\n\n\n\n\nThe results are similar to the ones obtained with the naive Bayes model, but there quite a few false negatives.\n\n\nCode\nresults = {'feature': features.columns,\n           'importance': rf.best_estimator_.named_steps['randomforestclassifier'].feature_importances_}\nimportance = pd.DataFrame(results).sort_values(by='importance', ascending=False)\nimportance['feature'] = importance['feature'].str.replace('category_', '').str.title()\nimportance\n\n\n\n\n\n\n\n\n\nfeature\nimportance\n\n\n\n\n3\nProtein\n0.228334\n\n\n13\nVegetable\n0.215688\n\n\n12\nPotato\n0.146860\n\n\n11\nPork\n0.091673\n\n\n5\nBreakfast\n0.088274\n\n\n1\nCarbohydrate\n0.056086\n\n\n0\nCalories\n0.054382\n\n\n6\nChicken\n0.048686\n\n\n2\nSugar\n0.045991\n\n\n4\nServings\n0.007990\n\n\n9\nMeat\n0.004375\n\n\n7\nDessert\n0.004152\n\n\n10\nOne Dish Meal\n0.004120\n\n\n8\nLunch/Snacks\n0.003389\n\n\n\n\n\n\n\n\n\nCode\nplot_importance = sns.barplot(x='importance', y='feature', data=importance, palette='summer')\nplot_importance.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\nplot_importance.set(xlabel = 'Importance',\n                    ylabel='',\n                    title='')\nplot_importance.figure.savefig(images_directory / \"importance.svg\")\n\n\n/var/folders/01/7w297lbs6v77_d56zq_nqjjc0000gn/T/ipykernel_23735/4124034061.py:1: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  plot_importance = sns.barplot(x='importance', y='feature', data=importance, palette='summer')\n\n\n\n\n\nThe most important features were Protein, Vegetable and Potato. Other categories like Lunch/Snacks, One Dish Meal, Dessert and Meal were not import. The nutritional variables (carbohydrates, calories, sugar, protein) did not have a high importance, but protein results impressively relevant.\n\n\nComparison\n\nThe two models performed similarly.\nThe naive Bayes model had a better precision (85.29% vs 84.38%), which is the most important metric.\nThe sensitivity was quite similar (79.17%).\nNaive Bayes is faster than random forest but the last one should be reviewed in the future because it is more complex, and hyperparameter tuning could improve it even more.\nRandom forest did not need preprocessing, provide the most important variables, and it is easy to interpret. So I would choose it as the best model. At this stage, I consider more important to detect the main drivers rather than the precision.\nHowever, I suggest to discuss with the team to decide if precision is paramount and then to choose naive Bayes.\n\n\n\nMetric to monitor in the business\n\nThe most important metric is precision because the business wants to correctly predict high-traffic recipes.\nWith the current data a good starting point is 85%.\nThe sensitivity must be regularly monitored because the business wants to avoid show low-traffic recipes in the main page of the website.\nMore details about the strategy proposed to the business are in the conclusions."
  },
  {
    "objectID": "posts/recipes/analysis.html#conclusions",
    "href": "posts/recipes/analysis.html#conclusions",
    "title": "High-traffic recipes prediction",
    "section": "Conclusions",
    "text": "Conclusions\n\nBefore continue, we need to check the data collection process to properly treat missing values and outliers.\nVegetables are the most popular category, followed by potato. Recipes with four servings are the most popular. So, the business should focus on healthy recipes for families.\n\nHave you considered clarifying your identity in the market? Perhaps advertising the business as a healthy family food company will help it to consolidate in this niche.\n\nRecipes with high protein seem more decisive.\nTasty Bytes should understand its customers better (i.e. collect more variables) to improve the model:\n\nWhat are the main age groups?\nDo people like new recipes every week or prefer that the current ones be enhanced?\n\n\n\nAction plan\n\nPut the previous recommendations in practice.\nTo determine whether the recommendations will help Tasty Bytes, we should perform an AB test!\nSeparate current customers into two groups:\n\nTo the first, we can continue to show the current website.\nTo the second group, we show the website with the most healthy recipes for the family.\n\nAfter that, we measure the click-through rate (CTR) in each group.\nWe can use the Bayesian techniques that I dominate to not only determine if there is a significant difference between the two groups, but also to quantify how strong it is!.\nIn parallel, we should review the data collection process and try to obtain new features because the current ones were not enough: there is an opportunity for improvement!"
  },
  {
    "objectID": "posts/fitness/analysis.html",
    "href": "posts/fitness/analysis.html",
    "title": "Fitness class attendance prediction",
    "section": "",
    "text": "I’m working for a fitness club chain. It offers a range of fitness classes in two capacities – 25 and 15.\nHere is the problem. The club has noticed that some of their classes are always fully booked. But fully booked classes often have a low attendance rate.\nThe fitness club wants to increase the number of spaces available for classes, so that new members can join. To achieve this, they need to predict whether a member will attend the class or not. If they perform this accurately, they can make another space available."
  },
  {
    "objectID": "posts/fitness/analysis.html#background",
    "href": "posts/fitness/analysis.html#background",
    "title": "Fitness class attendance prediction",
    "section": "",
    "text": "I’m working for a fitness club chain. It offers a range of fitness classes in two capacities – 25 and 15.\nHere is the problem. The club has noticed that some of their classes are always fully booked. But fully booked classes often have a low attendance rate.\nThe fitness club wants to increase the number of spaces available for classes, so that new members can join. To achieve this, they need to predict whether a member will attend the class or not. If they perform this accurately, they can make another space available."
  },
  {
    "objectID": "posts/fitness/analysis.html#dataset",
    "href": "posts/fitness/analysis.html#dataset",
    "title": "Fitness class attendance prediction",
    "section": "Dataset",
    "text": "Dataset\nThe dataset contains each record when a member registered for a fitness class. The data includes the following fields:\n\nbooking_id (nominal). The unique identifier of the booking.\nmonths_as_member (discrete). The number of months as member, minimum 1 month.\nweight (continuous). The member’s weight in kg, rounded to two decimal places. The minimum possible value is 40.00 kg.\ndays_before (discrete). The number of days before the class the member registered, minimum 1 day.\nday_of_week (ordinal). The day of the class.\ntime (ordinal). The time of day of the class. Either “AM” or “PM”.\ncategory (nominal). The category of the fitness class. One of “Yoga”, “Aqua”, “Strength”, “HIIT”, or “Cycling”.\nattended (nominal). Whether the member attended the class (1) or not (0).\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\nCode\nmy_palette = ['#10A19D', '#540375', '#FF7000', '#FFBF00', '#dd44aa', '#BEBEBE', '#112385']\nsns.set_theme(style='whitegrid')\nsns.set_palette(sns.color_palette(my_palette))\n\n\n\n\nCode\nfitness = pd.read_csv('data/fitness_class_2212.csv')\nfitness\n\n\n\n\n\n\n\n\n\nbooking_id\nmonths_as_member\nweight\ndays_before\nday_of_week\ntime\ncategory\nattended\n\n\n\n\n0\n1\n17\n79.56\n8\nWed\nPM\nStrength\n0\n\n\n1\n2\n10\n79.01\n2\nMon\nAM\nHIIT\n0\n\n\n2\n3\n16\n74.53\n14\nSun\nAM\nStrength\n0\n\n\n3\n4\n5\n86.12\n10\nFri\nAM\nCycling\n0\n\n\n4\n5\n15\n69.29\n8\nThu\nAM\nHIIT\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1495\n1496\n21\n79.51\n10\nFri\nAM\nHIIT\n0\n\n\n1496\n1497\n29\n89.55\n2\nMon\nAM\nStrength\n0\n\n\n1497\n1498\n9\n87.38\n4\nTue\nAM\nHIIT\n0\n\n\n1498\n1499\n34\n68.64\n14\nSun\nAM\nAqua\n0\n\n\n1499\n1500\n20\n94.39\n8\nThu\nAM\nCycling\n1\n\n\n\n\n1500 rows × 8 columns"
  },
  {
    "objectID": "posts/fitness/analysis.html#reading-data",
    "href": "posts/fitness/analysis.html#reading-data",
    "title": "Fitness class attendance prediction",
    "section": "Reading data",
    "text": "Reading data\nThe dataset is stored in a csv file.\n\n\nCode\nfitness.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 8 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   booking_id        1500 non-null   int64  \n 1   months_as_member  1500 non-null   int64  \n 2   weight            1480 non-null   float64\n 3   days_before       1500 non-null   object \n 4   day_of_week       1500 non-null   object \n 5   time              1500 non-null   object \n 6   category          1500 non-null   object \n 7   attended          1500 non-null   int64  \ndtypes: float64(1), int64(3), object(4)\nmemory usage: 93.9+ KB\n\n\nThe only missing values are in the column weight. So, there is no need to impute any other column.\n\nAuxiliary functions\nTo simplify the code, I will define some auxiliary functions.\n\n\nCode\ndef show_unique(column):\n    if column not in fitness.columns:\n        raise ValueError(f'Column {column} not in dataframe {fitness}')\n    return fitness[column].drop_duplicates().sort_values().reset_index(drop=True)\n\n\n\n\nCode\ndef show_sensitivity(conf_mat):\n    senstivity = conf_mat[1, 1] / (conf_mat[1, 0] + conf_mat[1, 1])\n    print(f'Sensitivity: {senstivity}')\n\n\n\n\nCode\ndef show_specificity(conf_mat):\n    specificity = conf_mat[0, 0] / (conf_mat[0, 0] + conf_mat[0, 1])\n    print(f'Specificity: {specificity}')\n\n\n\n\nCode\n\ndef show_roc_score(estimator, X_test, y_test):\n    y_pred = estimator.predict_proba(X_test)[:, 1]\n    print(f'ROC AUC score: {roc_auc_score(y_test, y_pred)}')\n\n\n\n\nCode\nplot_name = {\n    'booking_id': 'Booking ID',\n    'months_as_member': 'Months as member',\n    'weight': 'Weight',\n    'days_before': 'Days before',\n    'day_of_week': 'Day of week',\n    'time': 'Time',\n    'category': 'Category',\n    'attended': 'Attended'\n}"
  },
  {
    "objectID": "posts/fitness/analysis.html#data-validation",
    "href": "posts/fitness/analysis.html#data-validation",
    "title": "Fitness class attendance prediction",
    "section": "Data validation",
    "text": "Data validation\nI will check every variable in its own subsection. In general, there are few erros and the cleaning process is straightforward.\n\nbooking_id\nThere is no duplicates, and the values are unique. Also, the values are integers (even though the method describe transforms then into float).\n\n\nCode\nfitness['booking_id'].describe()\n\n\ncount    1500.000000\nmean      750.500000\nstd       433.157015\nmin         1.000000\n25%       375.750000\n50%       750.500000\n75%      1125.250000\nmax      1500.000000\nName: booking_id, dtype: float64\n\n\n\n\nCode\nfitness['booking_id'].duplicated().any()\n\n\nFalse\n\n\n\n\nmonths_as_member\nAs mentioned above, there are no missing values, so it is not necessary to impute. The minimum value is 1 as expected.\n\n\nCode\nfitness['months_as_member'].describe()\n\n\ncount    1500.000000\nmean       15.628667\nstd        12.926543\nmin         1.000000\n25%         8.000000\n50%        12.000000\n75%        19.000000\nmax       148.000000\nName: months_as_member, dtype: float64\n\n\n\n\nCode\nassert fitness['months_as_member'].min() &gt;= 1\n\n\n\n\nweight\nThere are missing values, so I will impute them with the mean. The minimum value is 40 as expected.\n\n\nCode\nfitness['weight'].describe()\n\n\ncount    1480.000000\nmean       82.610378\nstd        12.765859\nmin        55.410000\n25%        73.490000\n50%        80.760000\n75%        89.520000\nmax       170.520000\nName: weight, dtype: float64\n\n\n\n\nCode\nassert fitness['weight'].min() &gt;= 40.0\n\n\n\n\nCode\nfitness['weight'].isna().sum()\n\n\n20\n\n\n\n\nCode\nfitness['weight'].fillna(fitness['weight'].mean(), inplace=True)\n\n\n\n\nCode\nassert fitness['weight'].isna().sum() == 0\n\n\n\n\ndays_before\nIt is a discrete variable, but there is a problem with the values. Some of them ends with string days. Also, there are some values with spaces at the beginning. I will remove the string days as well as the spaces. The minimum value is 1, which makes sense.\n\n\nCode\nshow_unique('days_before')\n\n\n0           1\n1      1 days\n2          10\n3     10 days\n4          11\n5          12\n6     12 days\n7          13\n8     13 days\n9          14\n10    14 days\n11         15\n12         16\n13         17\n14          2\n15     2 days\n16         20\n17         29\n18          3\n19     3 days\n20          4\n21     4 days\n22          5\n23     5 days\n24          6\n25     6 days\n26          7\n27     7 days\n28          8\n29     8 days\n30          9\nName: days_before, dtype: object\n\n\n\n\nCode\nfitness['days_before'] = (\n    fitness['days_before']\n    .str.replace(r'\\s*days', '', regex=True)\n    .str.strip()\n    .astype(int)\n)\nshow_unique('days_before')\n\n\n0      1\n1      2\n2      3\n3      4\n4      5\n5      6\n6      7\n7      8\n8      9\n9     10\n10    11\n11    12\n12    13\n13    14\n14    15\n15    16\n16    17\n17    20\n18    29\nName: days_before, dtype: int64\n\n\n\n\nCode\nassert fitness['days_before'].min() &gt;= 1\n\n\n\n\nday_of_week\nThere are some misspellings. Since they are just three, a mapping is the simplest idea. I’ll also add the natural order of the days.\n\n\nCode\nshow_unique('day_of_week')\n\n\n0          Fri\n1         Fri.\n2          Mon\n3       Monday\n4          Sat\n5          Sun\n6          Thu\n7          Tue\n8          Wed\n9    Wednesday\nName: day_of_week, dtype: object\n\n\n\n\nCode\nday_map = {\n    'Fri.': 'Fri',\n    'Monday': 'Mon',\n    'Wednesday': 'Wed'\n}\n\n\n\n\nCode\nfitness['day_of_week'] = fitness['day_of_week'].replace(day_map)\nshow_unique('day_of_week')\n\n\n0    Fri\n1    Mon\n2    Sat\n3    Sun\n4    Thu\n5    Tue\n6    Wed\nName: day_of_week, dtype: object\n\n\n\n\nCode\nfitness['day_of_week'] = (\n    fitness['day_of_week']\n    .astype('category')\n    .cat.set_categories(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n    .cat.as_ordered()\n)\nshow_unique('day_of_week')\n\n\n0    Mon\n1    Tue\n2    Wed\n3    Thu\n4    Fri\n5    Sat\n6    Sun\nName: day_of_week, dtype: category\nCategories (7, object): ['Mon' &lt; 'Tue' &lt; 'Wed' &lt; 'Thu' &lt; 'Fri' &lt; 'Sat' &lt; 'Sun']\n\n\n\n\ntime\nThere are not errors, but I’ll add the order of time.\n\n\nCode\nshow_unique('time')\n\n\n0    AM\n1    PM\nName: time, dtype: object\n\n\n\n\nCode\nfitness['time'] = (\n    fitness['time'].astype('category')\n    .cat.set_categories(['AM', 'PM'])\n    .cat.as_ordered()\n)\nshow_unique('time')\n\n\n0    AM\n1    PM\nName: time, dtype: category\nCategories (2, object): ['AM' &lt; 'PM']\n\n\n\n\ncategory\nThere is an unknown category '-', so I’ll rename it as 'unknown'.\n\n\nCode\nshow_unique('category')\n\n\n0           -\n1        Aqua\n2     Cycling\n3        HIIT\n4    Strength\n5        Yoga\nName: category, dtype: object\n\n\n\n\nCode\nfitness['category'] = (\n    fitness['category']\n    .str.replace(r'-', 'unknown', regex=True)\n    .astype('category')\n    .cat.set_categories(['Yoga', 'Aqua', 'Strength', 'HIIT', 'Cycling', 'unknown'])\n)\nshow_unique('category')\n\n\n0        Yoga\n1        Aqua\n2    Strength\n3        HIIT\n4     Cycling\n5     unknown\nName: category, dtype: category\nCategories (6, object): ['Yoga', 'Aqua', 'Strength', 'HIIT', 'Cycling', 'unknown']\n\n\n\n\nattended\nI prefer using the values Yes and No instead of 1 and 0 in the analysis. This will enhance readability in the following plots. For the modelling stage, I will use the original values.\n\n\nCode\nshow_unique('attended')\n\n\n0    0\n1    1\nName: attended, dtype: int64\n\n\n\n\nCode\nfitness['attended'] = (\n    fitness['attended']\n    .replace({0: 'No', 1: 'Yes'})\n    .astype('category')\n    .cat.set_categories(['Yes', 'No'])\n    .cat.as_ordered()\n)\nshow_unique('attended')\n\n\n0    Yes\n1     No\nName: attended, dtype: category\nCategories (2, object): ['Yes' &lt; 'No']\n\n\n\n\nSummary\nThe original data has 1,500 rows and 8 columns. No line was removed, but some values were imputed\n\nbooking_id: Values are unique as expected\nmonths_as_member: Values are integers, there were no missing values, and the minimum value was 1\nweight: There were 20 missing values that I imputed with the mean. The minimum value was 40.0 as expected\ndays_before: Cleaned up text and converted to numeric, minimum value was 1 as expected. There were no missing values.\nday_of_week: Corrected misspellings, categories were “Mon”, “Tue”, “Wed”, “Thu”, “Fri”, “Sat” and “Sun” as expected. There were no missing values\ntime: No problem, the categories are “AM” and “PM”. There were no missing values\ncategory: I replaced '-' with “unknown”. The other categories are “Yoga”, “Aqua”, “Strength”, “HIIT”, or “Cycling”, as expected\nattended: Values were 0 and 1 as expected, no missing values."
  },
  {
    "objectID": "posts/fitness/analysis.html#data-analysis",
    "href": "posts/fitness/analysis.html#data-analysis",
    "title": "Fitness class attendance prediction",
    "section": "Data analysis",
    "text": "Data analysis\n\nTarget variable\nThe attendance is the target variable, so it’s more important to visualise its behaviour. There is a clear imbalance:\n\n\nCode\nplot_attended = sns.countplot(data=fitness, x='attended')\nplot_attended.bar_label(plot_attended.containers[0])\nplot_attended.set(xlabel=plot_name['attended'], ylabel='Count', title='Memers attendence')\n\n\n[Text(0.5, 0, 'Attended'),\n Text(0, 0.5, 'Count'),\n Text(0.5, 1.0, 'Memers attendence')]\n\n\n\n\n\nSome categories have a higher attendance than others.\n\n\nCode\nplot_category_attended = sns.countplot(data=fitness, y='category', hue='attended')\nplot_category_attended.set(xlabel='Count', ylabel=plot_name['category'], title='Category attendence')\n\n\n[Text(0.5, 0, 'Count'),\n Text(0, 0.5, 'Category'),\n Text(0.5, 1.0, 'Category attendence')]\n\n\n\n\n\nIn particular, HIIT has the lowest attendance, with more than 400 people. It is worth noting that there are always more members that don’t attend than members that do it.\n\n\nTime as members\nThere are some outliers in the months_as_member variable. So a boxplot is a good option to visualize its distribution.\n\n\nCode\nplot_months = sns.boxplot(data=fitness, x='months_as_member')\nplot_months.set(xlabel=plot_name['months_as_member'], ylabel='Count', title='Distribution of months as member')\n\n\n[Text(0.5, 0, 'Months as member'),\n Text(0, 0.5, 'Count'),\n Text(0.5, 1.0, 'Distribution of months as member')]\n\n\n\n\n\nThere are quite a few outliers, they correspond to long-term members. It’s possible that they are the ones who attend the most. On the other hand, recent members have in general about 10 months in the club.\n\n\nRelationship between variables\n\n\nCode\nplot_months_attended = sns.boxplot(data=fitness, x='months_as_member', y='attended')\nplot_months_attended.set(xlabel=plot_name['months_as_member'], ylabel=plot_name['attended'],\n                         title='Distribution of months as member by attendence')\n\n\n[Text(0.5, 0, 'Months as member'),\n Text(0, 0.5, 'Attended'),\n Text(0.5, 1.0, 'Distribution of months as member by attendence')]\n\n\n\n\n\nAs expected, the long-term members are the ones who attend the most. There is a clear difference between the median of the two groups. This is a good indicator that the variable months_as_member is a good predictor of the attendance. Instead of performing a t-test, I will use it directly in the modelling stage.\n\n\nCode\nplot_weight_attended = sns.scatterplot(data=fitness, x='months_as_member', y='weight', hue='attended', alpha=0.3)\nplot_weight_attended.set(xlabel=plot_name['months_as_member'], ylabel=plot_name['weight'],\n                         title='Relation between months as member and weight')\n\n\n[Text(0.5, 0, 'Months as member'),\n Text(0, 0.5, 'Weight'),\n Text(0.5, 1.0, 'Relation between months as member and weight')]\n\n\n\n\n\nPeople that attend more and has more months in the club tend to have a lower weight. This is a good indicator that the variable weight is a good predictor of the attendance. Poeple that has recently joined the club has a higher weight and usually don’t attend.\n\n\nCode\nplot_days_weight = sns.scatterplot(data=fitness, x='days_before', y='weight', hue='attended', alpha=0.5)\nplot_days_weight.set(xlabel=plot_name['days_before'], ylabel=plot_name['weight'],\n                         title='Relation between days before and weight')\n\n\n[Text(0.5, 0, 'Days before'),\n Text(0, 0.5, 'Weight'),\n Text(0.5, 1.0, 'Relation between days before and weight')]\n\n\n\n\n\nThere is no clear relationship between the days before the registration and the attendance. However, the person who registered 30 days before didn’t attend and the people who registered 1 day before attended. This variable might not be an important predictor, but it contains some information.\n\n\nCode\nfrom matplotlib.ticker import FuncFormatter\n\nplot_weight_attended = sns.kdeplot(data=fitness, x=\"weight\", hue=\"attended\", fill=True, common_norm=False)\nplot_weight_attended.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\nplot_weight_attended.set(xlabel=plot_name['weight'], ylabel='Count', title='Distribution of weight by attendence')\n\n\n[Text(0.5, 0, 'Weight'),\n Text(0, 0.5, 'Count'),\n Text(0.5, 1.0, 'Distribution of weight by attendence')]\n\n\n\n\n\nAlthough the distribution doesn’t change much, the people with the lowest weight usually attend.\n\n\nCode\nimport numpy as np\n\nplot_weight_days = sns.barplot(data=fitness, x='weight', y='day_of_week', estimator=np.std, errorbar=None)\nplot_weight_days.set(xlabel=plot_name['weight'],\n                     ylabel=plot_name['day_of_week'],\n                     title='Standard deviation of weight by day of week'\n                     )\n\n\n[Text(0.5, 0, 'Weight'),\n Text(0, 0.5, 'Day of week'),\n Text(0.5, 1.0, 'Standard deviation of weight by day of week')]\n\n\n\n\n\nSunday is when the weight is more volatile, but the difference is not significant between the other days.\n\n\nCode\nplot_before_time = sns.barplot(data=fitness,\n                               x='time',\n                               y='days_before',\n                               estimator='median',\n                               palette=sns.color_palette(my_palette[3:5]),\n                               errorbar=None,\n                               hue='time',\n                               legend=False,\n                               )\nplot_before_time.bar_label(plot_before_time.containers[0])\nplot_before_time.set(xlabel=plot_name['time'],\n                     ylabel=plot_name['days_before'],\n                     title='Median of days before by time')\n\n\n[Text(0.5, 0, 'Time'),\n Text(0, 0.5, 'Days before'),\n Text(0.5, 1.0, 'Median of days before by time')]\n\n\n\n\n\nThe classes in the morning are usually booked with more days in advance than the classes in the afternoon. This is a good indicator that the variable time adds new information to the model."
  },
  {
    "objectID": "posts/fitness/analysis.html#data-modelling",
    "href": "posts/fitness/analysis.html#data-modelling",
    "title": "Fitness class attendance prediction",
    "section": "Data Modelling",
    "text": "Data Modelling\nSince we are trying to predict whether a member will attend the class or not, this is a classification problem. Before propose a model, I will preprocess the data for the task. The main goal is to correctly predict attendance, so the metric is sensitivity. Nevertheless, I will also use the area under the ROC curve since the target is imbalanced.\n\nPreprocessing\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\n\n\n\nCode\nfeatures = fitness.drop(columns=['booking_id', 'attended'])\nfeatures\n\n\n\n\n\n\n\n\n\nmonths_as_member\nweight\ndays_before\nday_of_week\ntime\ncategory\n\n\n\n\n0\n17\n79.56\n8\nWed\nPM\nStrength\n\n\n1\n10\n79.01\n2\nMon\nAM\nHIIT\n\n\n2\n16\n74.53\n14\nSun\nAM\nStrength\n\n\n3\n5\n86.12\n10\nFri\nAM\nCycling\n\n\n4\n15\n69.29\n8\nThu\nAM\nHIIT\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1495\n21\n79.51\n10\nFri\nAM\nHIIT\n\n\n1496\n29\n89.55\n2\nMon\nAM\nStrength\n\n\n1497\n9\n87.38\n4\nTue\nAM\nHIIT\n\n\n1498\n34\n68.64\n14\nSun\nAM\nAqua\n\n\n1499\n20\n94.39\n8\nThu\nAM\nCycling\n\n\n\n\n1500 rows × 6 columns\n\n\n\n\n\nCode\nfeatures = pd.get_dummies(features, drop_first=True, dtype='int')\nfeatures\n\n\n\n\n\n\n\n\n\nmonths_as_member\nweight\ndays_before\nday_of_week_Tue\nday_of_week_Wed\nday_of_week_Thu\nday_of_week_Fri\nday_of_week_Sat\nday_of_week_Sun\ntime_PM\ncategory_Aqua\ncategory_Strength\ncategory_HIIT\ncategory_Cycling\ncategory_unknown\n\n\n\n\n0\n17\n79.56\n8\n0\n1\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\n1\n10\n79.01\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n16\n74.53\n14\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n\n\n3\n5\n86.12\n10\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n4\n15\n69.29\n8\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1495\n21\n79.51\n10\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n1496\n29\n89.55\n2\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n1497\n9\n87.38\n4\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n1498\n34\n68.64\n14\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n\n\n1499\n20\n94.39\n8\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n\n\n1500 rows × 15 columns\n\n\n\n\n\nCode\ntarget = fitness['attended'].replace({'Yes': 1, 'No': 0}).astype('int')\ntarget\n\n\n0       0\n1       0\n2       0\n3       0\n4       0\n       ..\n1495    0\n1496    0\n1497    0\n1498    0\n1499    1\nName: attended, Length: 1500, dtype: int64\n\n\n\n\nCode\nseed = 1\nX = features.values\ny = target.values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\nkf = KFold(n_splits=10, random_state=seed, shuffle=True)\n\n\n\n\nBaseline model\nThe exploratory analysis revealed that the relationships between the target variable and the predictors were not linear. For this reason I decided to implement a flexible model like K-nearest neighbours. I will also use a 10-fold cross-validation to avoid overfitting.\n\n\nCode\nparam_grid = {'n_neighbors': range(1, 10)}\nknearest = KNeighborsClassifier()\ncv = GridSearchCV(knearest, param_grid, cv=kf, scoring='roc_auc')\ncv.fit(X_train, y_train)\nprint(f'Best parameter: {cv.best_params_}')\nprint(f'Best score: {cv.best_score_:0.2f}')\nbest_knearest = cv.best_estimator_\npredictions = best_knearest.predict(X_test)\nconfusion = confusion_matrix(y_test, predictions)\nconfusion\n\n\nBest parameter: {'n_neighbors': 9}\nBest score: 0.77\n\n\narray([[270,  40],\n       [ 72,  68]])\n\n\n\n\nCode\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels = best_knearest.classes_)\ndisp.plot()\nshow_sensitivity(confusion)\nshow_specificity(confusion)\nshow_roc_score(best_knearest, X_test, y_test)\n\n\nSensitivity: 0.4857142857142857\nSpecificity: 0.8709677419354839\nROC AUC score: 0.7604377880184332\n\n\n\n\n\nTo see the results, a confusion matrix is a good option.The main problem is that the model cannot correctly detect people that attend the class. Also, the best option seems to be 9 neighbours, which looks like a lot, reducing interpretability.\n\n\nAlternative model\nThe random forest model seems to me a good alternative since it allows eliminating correlations between the predictors, giving better interpretability and even analyzing the importance of the variables in a more in-depth analysis and in a non-technical presentation with the client.\n\n\nCode\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state=seed, n_jobs=-1, min_samples_leaf=0.01)\nparam_grid = {'max_depth': [5, 20, 30],\n              'n_estimators': [50, 100, 200, 300]}\ncv = GridSearchCV(rf, param_grid, cv=kf, scoring='roc_auc')\ncv.fit(X_train, y_train)\nprint(f'Best parameter: {cv.best_params_}')\nprint(f'Best score: {cv.best_score_}')\n\n\nBest parameter: {'max_depth': 20, 'n_estimators': 200}\nBest score: 0.8026098200988698\n\n\n\n\nCode\nbest_rf = cv.best_estimator_\npredictions = best_rf.predict(X_test)\nconfusion = confusion_matrix(y_test, predictions)\nconfusion\n\n\narray([[265,  45],\n       [ 72,  68]])\n\n\n\n\nCode\nsenstivity = confusion[1, 1] / (confusion[1, 0] + confusion[1, 1])\nspecificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1])\nprint(f'Sensitivity: {senstivity}')\nprint(f'Specificity: {specificity}')\n\n\nSensitivity: 0.4857142857142857\nSpecificity: 0.8548387096774194\n\n\n\n\nCode\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels = best_rf.classes_)\ndisp.plot()\n\n\n&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15dd67850&gt;\n\n\n\n\n\nThe results are quite similar. The main issue is sensitivity. Tunning hyperparameters didn’t improve the results.\n\n\nResults\nBoth models had problems detecting people who do attend classes (low sensitivity), which is evident in the fact that there are many false negatives (in fact, they exceed the true positives).\nIn contrast, they were able to correctly predict non-attendance (high specificity): in the context of the company this is the most important task. The two models had a high value of area under the roc curve, so in general their performance is good.\nThe models were tied in specificity, K-nearest neighbours gained in specificity, but random forests were better for the roc auc. I consider that the best model is k nearest neighbors since specificity is the most important metric for the company, it is considerably faster to train and its operation is easier to explain to decision makers."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My projects",
    "section": "",
    "text": "I deployed a spam detector online!\n\n\n\n\n\n\n\ndjango\n\n\nML\n\n\nanalysis\n\n\nclassification\n\n\n\n\n\n\n\n\n\n\n\nMauricio Alejandro Prieto Palacios\n\n\n\n\n\n\n  \n\n\n\n\nHigh-traffic recipes prediction\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nMauricio Alejandro Prieto Palacios\n\n\n\n\n\n\n  \n\n\n\n\nFitness class attendance prediction\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nMauricio Alejandro Prieto Palacios\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Although I studied actuarial science, I consider myself more of a mathematician. I have worked as a data scientist and programmer for over two years.\nYou can check my professional data science certification here. Find out more details about the skills evaluated here.\nI’ve been working as a freelance for several months. Feel free to have a look my clients’ opinions about my work."
  },
  {
    "objectID": "skills.html",
    "href": "skills.html",
    "title": "My skills",
    "section": "",
    "text": "Read more about the tools I use and how.\n\nPython: I love this language because I am able to use it for different purposes like data science, OOP and web development. I consider myself proficient and it is my main programming language. In the machine learning life cycle I can ingest, validate, clean and transform data as well as train models and asses them.\nR: Data manipulation, EDA and Statistical analysis can be carried out in a particularly easy and elegant way with R. This language has a lot of unique features I like to use in a functional programming style, allowing me to create neat code. Prominently, the plots I have created with ggplot are flawless and a pleasure to design.\nSQL: I can build and design relational databases from scratch. I like to keep everything in the right place, bringing advantages like simpler queries and smaller URMs. I like using raw SQL but I often find more useful ORMs like SQL alchemy because the workflow inside python becomes nimbler and easier to debug.\nPython package development: I strongly encourage companies to build their own private packages. They are fully-tested solutions for common tasks. Here I use further techniques like unit testing —with pytest— and CI —with GitHub actions— that guarantees they work appropriate and efficiently.\nDjango: Even though I am not a web developer, I use Django for machine learning models deployment. I like creating views and templates with IDE assistance and I have even deployed an spam detector.\nWeb scraping: I understand how HTML is structured and can exploit it to convert messy data into tidy and reliable data. I can also perform web crawling to get a big amount of data in seconds through websites with several structure or with a lot of pages. I have automated several different tasks with specialised tools like playwright or selenium, saving hours of work every month.\nCLI: I use it every day. It is a very efficient way to work with files and automate tasks. When I work for a client, I often start by giving them a CLI app since is the simplest way to wrap the code and allows them to use the solution as soon as possible. In my view this is the most basic and usted tool in software development.\nUnit testing: Ensuring my code works as I expect is paramount, but the real benefit of unit testing is that I can extend the code confidently. In data science I often have to create a lot of new functions and here is when testing becomes very useful.\nGit: All of my projects are saved online thanks to git. I have experience solving the most common problems in VCS. I like writing clear and short comming messages so that the history of the project is well documented.\nGitHub Actions (CI): There are several tasks that I automate with this tool. It is a great way to save time and ensure the quality of the code when it leaves my computer. I use it mainly for package development.\nDocker: Working in an isolated environment allows me to be sure that my code works in other computers. I have created a couple of containers and they let me sending machine learning models that work independently.\nIDE: Productivity is really important for me and that is why I love PyCharm. It is reliable and saves me a lot time every day. I have spent some time learning how to use it in the best possible way and it keeps paying dividends."
  },
  {
    "objectID": "university.html",
    "href": "university.html",
    "title": "portfolio",
    "section": "",
    "text": "University Diploma\n\n\n\n\nUniversity Performance\n\n\n\n\nProfessional License"
  }
]